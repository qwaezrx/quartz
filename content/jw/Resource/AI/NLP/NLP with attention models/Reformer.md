---
tags:
  - AI/Transformer
---

## The Reversible Transformer

- Using this model, you can fit up to 1 million tokens on a single 16GB GPU (enough to fit in an entire book)

- [[LSH Attention]]: Reduce complexity of attending over long sequences.
- [[Reversible Residual Layer]]: To efficiently use the memory available



![[Pasted image 20230908205537.png]]



