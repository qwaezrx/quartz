---
tags:
  - "#Open_Source"
  - AI/GAI/LLM
  - AI/Transformer/Decoder
parameters: 176000000000
author: Bigscience
date: 2022-11-10
---


BLOOM shares the same structure as [[GPT-3]] but instead of using sparse attention, BLOOM uses full attention network, which is better suited for modeling long sequences.

- able to generate:
	- 46 natural languages
	- 13 programming languages


## See More
- https://bigscience.huggingface.co/blog/bloom
- https://huggingface.co/bigscience/bloom