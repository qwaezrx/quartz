
aka. Autoregressive Language Model


Model the probability of the next token given previous tokens, hence, left-to-right language modeling.

- More suitable for generative tasks than [[Encoder Model]].


## Autoregressive Language Models

```dataview
TABLE date, parameters, author
FROM #Transformer/Decoder 
```

