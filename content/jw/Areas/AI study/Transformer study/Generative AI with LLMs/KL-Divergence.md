---
aliases:
  - Kullback-Leibler Divergence
tags:
  - AI
---

## Kullback-Leibler Divergence

KL-Divergence measures the difference between two probability distributions

![[Pasted image 20230905205628.png]]

KL-Divergence often encountered when using the [[PPO]] (Proximal Policy Optimization) algorithm.

In the context of PPO, KL-Divergence plays a crucial role in guiding the optimization process to ensure that the update policy does not deviate too much from the original policy.



## Read more
- https://huggingface.co/blog/trl-peft
- [Kullbackâ€“Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)
- [Balancing reconstruction error and Kullback-Leibler divergence in Variational Autoencoders](https://arxiv.org/abs/2002.07514) (Asperti & Trentin, 2020)

